{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oczAvZviIqnU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/godwinkhalko/miniconda3/envs/base_1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from PIL import Image\n",
        "from timm.models.vision_transformer import VisionTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "warnings.filterwarnings(\"ignore\", message=\"numerical errors at iteration 0\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pSjZycBFIC2u"
      },
      "outputs": [],
      "source": [
        "# Semantic Segmentation Model\n",
        "class SemanticSegmentor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.segmentation_model = deeplabv3_resnet50(pretrained=True)\n",
        "        # self.segmentation_model.eval()  # Freeze weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            seg_map = self.segmentation_model(x)['out']\n",
        "        return seg_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kSk3hiq9Wiq0"
      },
      "outputs": [],
      "source": [
        "#Multimodal Feature Fusion (MFF)\n",
        "class MultimodalFusion(nn.Module):\n",
        "    def __init__(self, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(embed_dim, embed_dim)  # f(.) projection\n",
        "        self.back_projection = nn.Linear(embed_dim, embed_dim)  # g(.) back-projection\n",
        "\n",
        "        # Attention module\n",
        "        self.attention_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * embed_dim, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_dim, 2),\n",
        "            nn.Softmax(dim=1)  # Generates [w_rgb, w_seg]\n",
        "        )\n",
        "\n",
        "    def forward(self, rgb_cls, seg_cls):\n",
        "        # Compute modality attention\n",
        "        att_input = torch.cat([rgb_cls, seg_cls], dim=1)\n",
        "        weights = self.attention_mlp(att_input)  # [batch, 2]\n",
        "        w_rgb, w_seg = weights[:, 0].unsqueeze(1), weights[:, 1].unsqueeze(1)\n",
        "\n",
        "        # Weighted CLS token fusion (final layer)\n",
        "        rgb_final = (1 + w_rgb) * rgb_cls\n",
        "        seg_final = (1 + w_seg) * seg_cls\n",
        "        fmm = torch.cat([rgb_final, seg_final], dim=1)  # Final fused feature\n",
        "\n",
        "        return fmm\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YCrZMwadMXhr"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, dim_model: int, dropout_p: float = 0.1, max_len: int=1000):\n",
        "        \"\"\"Initializes the positional embedding layer to enrich data fed into transformers\n",
        "           with positional information.\n",
        "        Args:\n",
        "            dim_model (int): model dimension\n",
        "            dropout_p (float, optional): dropout for all embeddings. Defaults to 0.1.\n",
        "            max_len (int, optional): determines how far the position can influence other tokens. Defaults to 1000.\n",
        "        Note:\n",
        "            This code is a modified version of: `<https://pytorch.org/tutorials/beginner/transformer_tutorial.html>`_.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        # Encoding\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1)\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model)\n",
        "\n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "\n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "\n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_parameter('pos_encoding', nn.Parameter(pos_encoding, requires_grad=False))\n",
        "\n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"Generates positional embeddings.\n",
        "        Args:\n",
        "            token_embedding (torch.tensor): original embeddings\n",
        "        Returns:\n",
        "            torch.tensor: transformed embeddings\n",
        "        \"\"\"\n",
        "        # Residual connection + positional encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0jU_jM1rbuH4"
      },
      "outputs": [],
      "source": [
        "class MultimodalTransformer(nn.Module):\n",
        "    def __init__(self, img_size, patch_size = 8, vit_model: str = \"vit_base_patch16_224\", embed_dim: int = 768, num_layers: int = 3):\n",
        "        super(MultimodalTransformer, self).__init__()\n",
        "\n",
        "        # Load pre-trained ViT models for RGB and Semantic maps\n",
        "        self.rgb_transformer = VisionTransformer(img_size=img_size, patch_size=patch_size, embed_dim=embed_dim, depth=num_layers, num_heads=6, mlp_ratio=4)\n",
        "        self.seg_transformer = VisionTransformer(img_size=img_size, patch_size=patch_size, embed_dim=embed_dim, in_chans=1, depth=num_layers, num_heads=6, mlp_ratio=4)\n",
        "\n",
        "        # Projection layers to align CLS token dimensions\n",
        "        self.cls_projection = nn.Linear(embed_dim, embed_dim)  # f(.) projection\n",
        "        self.back_projection = nn.Linear(embed_dim, embed_dim)  # g(.) back-projection\n",
        "\n",
        "        # Attention fusion of CLS token from the last layer\n",
        "        self.fusion_module = MultimodalFusion()\n",
        "\n",
        "        #Positional Encoder\n",
        "        self.pos_encoder = PositionalEncoder(dim_model=embed_dim)\n",
        "\n",
        "\n",
        "    def forward(self, rgb_input, seg_input):\n",
        "        # Extract embeddings from both transformers\n",
        "        rgb_tokens = self.rgb_transformer.patch_embed(rgb_input)\n",
        "        seg_tokens = self.seg_transformer.patch_embed(seg_input)\n",
        "\n",
        "        cls_rgb = self.rgb_transformer.cls_token.expand(rgb_tokens.shape[0], -1, -1)\n",
        "        cls_seg = self.seg_transformer.cls_token.expand(seg_tokens.shape[0], -1, -1)\n",
        "\n",
        "        # Positional embedding\n",
        "        #Concat the cls token for resective tokens(rgb or seg)\n",
        "        rgb_tokens = torch.cat([cls_rgb, rgb_tokens], dim=1)\n",
        "        seg_tokens = torch.cat([cls_seg, seg_tokens], dim=1)\n",
        "        #add the positional embeddings\n",
        "        rgb_tokens = self.pos_encoder(rgb_tokens)\n",
        "        seg_tokens = self.pos_encoder(seg_tokens)\n",
        "\n",
        "        for layer in range(len(self.rgb_transformer.blocks)):\n",
        "            rgb_tokens = self.rgb_transformer.blocks[layer](rgb_tokens)\n",
        "            seg_tokens = self.seg_transformer.blocks[layer](seg_tokens)\n",
        "\n",
        "            # Extract CLS tokens after each layer\n",
        "            cls_rgb = self.cls_projection(rgb_tokens[:, 0])\n",
        "            cls_seg = self.cls_projection(seg_tokens[:, 0])\n",
        "\n",
        "            # Sum CLS tokens and append back to patch tokens\n",
        "            fused_cls = self.back_projection(cls_rgb + cls_seg)\n",
        "            rgb_tokens = torch.cat([fused_cls.unsqueeze(1), rgb_tokens[:, 1:]], dim=1)\n",
        "            seg_tokens = torch.cat([fused_cls.unsqueeze(1), seg_tokens[:, 1:]], dim=1)\n",
        "\n",
        "        # Final CLS tokens from last layer\n",
        "        cls_rgb = rgb_tokens[:, 0]\n",
        "        cls_seg = seg_tokens[:, 0]\n",
        "\n",
        "        # Attention fusion of the cls tokens from the last layer\n",
        "        fmm = self.fusion_module(cls_rgb, cls_seg)\n",
        "\n",
        "        return fmm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S5pNS7XssWg2"
      },
      "outputs": [],
      "source": [
        "#Define a mlp layer that predict a class based on the input\n",
        "class mlp(nn.Module):\n",
        "  def __init__(self, input_dim = 1536, output_dim = 10):\n",
        "    super(mlp, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, 1024)\n",
        "    self.fc2 = nn.Linear(1024, 2048)\n",
        "    self.fc3 = nn.Linear(2048, output_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aINp2nc5qL4N"
      },
      "outputs": [],
      "source": [
        "#Define a classifier for based on the Semantic Segmentor and multimodal model.\n",
        "class MultiModalClassifier(nn.Module):\n",
        "  def __init__(self, input_dim = 256,feature_size = 1536,  output_dim = 2781):\n",
        "    super(MultiModalClassifier, self).__init__()\n",
        "    self.sematic_segmantic = SemanticSegmentor()\n",
        "    self.multimodal = MultimodalTransformer(input_dim)\n",
        "    self.mlp = mlp(feature_size, output_dim)\n",
        "\n",
        "  # x is the rgb image of the shape (batch_size, channels, height, width)\n",
        "  def forward(self, x):\n",
        "    #Generate the semantic maps for the input images\n",
        "\n",
        "    semantic_output = self.sematic_segmantic(x)\n",
        "    semantic_map = torch.argmax(semantic_output.squeeze(), dim=1).unsqueeze(1).float()\n",
        "\n",
        "    # Pass the semantic map and the rgb images through the MultimodalTransformer\n",
        "    multimodal_output = self.multimodal(x, semantic_map)# (batch, 1536)\n",
        "\n",
        "    # pass throught the mlp to get the classes\n",
        "    output = self.mlp(multimodal_output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99dNXKhPuVw2"
      },
      "source": [
        "## Working with the Data\n",
        "Prepare the data for the training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def denormalize(img_tensor):\n",
        "    \"\"\"Reverse normalization using ImageNet stats\"\"\"\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    return img_tensor * std + mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageLabelDataset(Dataset):\n",
        "    def __init__(self, image_dir, dataframe, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img_filename = row['filename']\n",
        "        label = row['polygon_label']\n",
        "        img_path = os.path.join(self.image_dir, img_filename)\n",
        "        \n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        \n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDataset():\n",
        "    img_path = '/home/godwinkhalko/DLCV/00'\n",
        "    label_path = '/home/godwinkhalko/DLCV/labelled_points.xlsx'\n",
        "    \n",
        "    df = pd.read_excel(label_path, dtype={'id': str})\n",
        "    \n",
        "    image_files = os.listdir(img_path)\n",
        "    id_to_filename = {}\n",
        "    for f in image_files:\n",
        "        id_ = os.path.splitext(f)[0] \n",
        "        id_to_filename[id_] = f\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    df['polygon_label'] = label_encoder.fit_transform(df['polygon_label'])\n",
        "\n",
        "    joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "    filtered_df = df[df['id'].isin(id_to_filename.keys())]\n",
        "\n",
        "\n",
        "    filtered_df['filename'] = filtered_df['id'].map(id_to_filename)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    dataset = ImageLabelDataset(image_dir=img_path, dataframe=filtered_df, transform=transform)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def showImages(dataloader):\n",
        "    images, labels = next(iter(dataloader))\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
        "\n",
        "    for i in range(5):\n",
        "        image = denormalize(images[i]).cpu().numpy()\n",
        "        image = np.transpose(image, (1, 2, 0))\n",
        "        image = np.clip(image, 0, 1)\n",
        "        \n",
        "        axs[i].imshow(image)\n",
        "        axs[i].set_title(f\"Label: {labels[i].item()}\")\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v74Ks_29zN5"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CYqY5bOO_ubQ"
      },
      "outputs": [],
      "source": [
        "def train(model, dataset, epochs, batch_size, optimizer, criterion, save_point = 500):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Define the Dataloader\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    checkpoint_path = \"/home/godwinkhalko/DLCV/checkpoint.pth\"\n",
        "    modified_checkpoint_path = \"/home/godwinkhalko/DLCV/mod_checkpoint.pth\"\n",
        "    # print(f\"Checking if a checkpoint exists\")\n",
        "    # if os.path.exists(checkpoint_path):\n",
        "\n",
        "    #     print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
        "    #     checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    #     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        \n",
        "    #     if 'optimizer_state_dict' in checkpoint:\n",
        "    #         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    #     start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "    #     print(f\"Checkpoint loaded, resuming from epoch {start_epoch}\")\n",
        "    # else:\n",
        "    #     print(\"No checkpoint found, starting from scratch.\")\n",
        "    #     start_epoch = 0\n",
        "\n",
        "    print(\"Started Training\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # ✅ Ensure model is in training mode\n",
        "        optimizer.zero_grad()  # ✅ Reset gradients before batch loop\n",
        "\n",
        "        training_loss_batch = []\n",
        "        training_accuracies_batch = []\n",
        "\n",
        "        print(f\"Started training for {epoch + 1}\")\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()  # ✅ Reset gradients for every batch\n",
        "\n",
        "            # Forward pass\n",
        "            output= model(data)\n",
        "\n",
        "            loss = criterion(output, target) \n",
        "\n",
        "            training_loss_batch.append(loss.item())\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()  # ✅ Update weights\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predicted_classes = torch.argmax(output, dim=1)\n",
        "            accuracy = accuracy_score(target.cpu().numpy(), predicted_classes.cpu().numpy())\n",
        "            training_accuracies_batch.append(accuracy)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item()}, Accuracy: {accuracy}\", end=\"\\r\")\n",
        "            \n",
        "            if batch_idx % save_point == 0:\n",
        "                torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    }, modified_checkpoint_path)\n",
        "        # Average training loss and accuracy\n",
        "        train_loss.append(np.mean(training_loss_batch))\n",
        "        train_accuracy.append(np.mean(training_accuracies_batch))\n",
        "        print(f\"\\n Epoch {epoch+1}/{epochs}, Training Loss: {np.mean(training_loss_batch)}, Training Accuracy: {np.mean(training_accuracies_batch)}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UGK96b2xH-I",
        "outputId": "5d847d41-1a39-4cf9-8007-bb3c8a789229"
      },
      "outputs": [],
      "source": [
        "#Initialize the training parameters\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "\n",
        "#Initlaize the models and stuff\n",
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiModalClassifier()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_dataset = getDataset()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "zHkbL7lmxVIq",
        "outputId": "44ef47d1-6aa5-4d23-cb8f-213fd66a115a"
      },
      "outputs": [],
      "source": [
        "# #Run the training\n",
        "# trained_model = train(model=model,\n",
        "#                         dataset=train_dataset,\n",
        "#                         epochs=100,\n",
        "#                         batch_size=batch_size,\n",
        "#                         optimizer=optimizer,\n",
        "#                         criterion=criterion,\n",
        "#                         save_point=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiModalClassifier(\n",
              "  (sematic_segmantic): SemanticSegmentor(\n",
              "    (segmentation_model): DeepLabV3(\n",
              "      (backbone): IntermediateLayerGetter(\n",
              "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "        (layer1): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer2): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer3): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (4): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (5): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer4): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (classifier): DeepLabHead(\n",
              "        (0): ASPP(\n",
              "          (convs): ModuleList(\n",
              "            (0): Sequential(\n",
              "              (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (1): ASPPConv(\n",
              "              (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (2): ASPPConv(\n",
              "              (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (3): ASPPConv(\n",
              "              (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (4): ASPPPooling(\n",
              "              (0): AdaptiveAvgPool2d(output_size=1)\n",
              "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (3): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (project): Sequential(\n",
              "            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU()\n",
              "            (3): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (3): ReLU()\n",
              "        (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (aux_classifier): FCNHead(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "        (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (multimodal): MultimodalTransformer(\n",
              "    (rgb_transformer): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "    )\n",
              "    (seg_transformer): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(8, 8), stride=(8, 8))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "    )\n",
              "    (cls_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (back_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (fusion_module): MultimodalFusion(\n",
              "      (projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (back_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (attention_mlp): Sequential(\n",
              "        (0): Linear(in_features=1536, out_features=768, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=768, out_features=2, bias=True)\n",
              "        (3): Softmax(dim=1)\n",
              "      )\n",
              "    )\n",
              "    (pos_encoder): PositionalEncoder(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (mlp): mlp(\n",
              "    (fc1): Linear(in_features=1536, out_features=1024, bias=True)\n",
              "    (fc2): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "    (fc3): Linear(in_features=2048, out_features=2781, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_path = '/home/godwinkhalko/DLCV/test.csv'\n",
        "img_path = '/home/godwinkhalko/DLCV/00'\n",
        "\n",
        "df = pd.read_csv(label_path, dtype={'id': str})\n",
        "\n",
        "image_files = os.listdir(img_path)\n",
        "id_to_filename = {}\n",
        "for f in image_files:\n",
        "    id_ = os.path.splitext(f)[0] \n",
        "    id_to_filename[id_] = f\n",
        "\n",
        "filtered_df = df[df['id'].isin(id_to_filename.keys())]\n",
        "filtered_df['filename'] = filtered_df['id'].map(id_to_filename)\n",
        "filtered_df_mod = filtered_df[[\"id\", \"latitude\", \"longitude\", \"filename\"]]\n",
        "\n",
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Model\n",
        "model = MultiModalClassifier()\n",
        "\n",
        "checkpoint = torch.load(\"/home/godwinkhalko/DLCV/Trained_Model.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>547473234108938</td>\n",
              "      <td>-16.336027</td>\n",
              "      <td>45.628280</td>\n",
              "      <td>547473234108938.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>826109781317024</td>\n",
              "      <td>50.855687</td>\n",
              "      <td>56.147997</td>\n",
              "      <td>826109781317024.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1006398440000844</td>\n",
              "      <td>37.956651</td>\n",
              "      <td>14.954485</td>\n",
              "      <td>1006398440000844.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2943891539215481</td>\n",
              "      <td>12.373333</td>\n",
              "      <td>-8.909906</td>\n",
              "      <td>2943891539215481.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>122945119799579</td>\n",
              "      <td>7.510295</td>\n",
              "      <td>99.061884</td>\n",
              "      <td>122945119799579.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id   latitude  longitude              filename\n",
              "0   547473234108938 -16.336027  45.628280   547473234108938.jpg\n",
              "1   826109781317024  50.855687  56.147997   826109781317024.jpg\n",
              "2  1006398440000844  37.956651  14.954485  1006398440000844.jpg\n",
              "3  2943891539215481  12.373333  -8.909906  2943891539215481.jpg\n",
              "4   122945119799579   7.510295  99.061884   122945119799579.jpg"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df_mod = filtered_df[[\"id\", \"latitude\", \"longitude\", \"filename\"]]\n",
        "filtered_df_mod.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestImageLabelDataset(Dataset):\n",
        "    def __init__(self, image_dir, dataframe, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img_filename = row['filename']\n",
        "        img_path = os.path.join(self.image_dir, img_filename)\n",
        "        \n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        \n",
        "        return image, row['id'], row['latitude'], row['longitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model.eval()\n",
        "results = []\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "dataset = TestImageLabelDataset(image_dir=\"/home/godwinkhalko/DLCV/00\", dataframe=filtered_df_mod, transform=transform)\n",
        "# subset =Subset(dataset, list(range(10)))\n",
        "\n",
        "test_loader = DataLoader(dataset=dataset, batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch: 0 / 6567\n",
            "\n",
            "Batch: 1 / 6567\n",
            "\n",
            "Batch: 2 / 6567\n",
            "\n",
            "Batch: 3 / 6567\n",
            "\n",
            "Batch: 4 / 6567\n",
            "\n",
            "Batch: 5 / 6567\n",
            "\n",
            "Batch: 6 / 6567\n",
            "\n",
            "Batch: 7 / 6567\n",
            "\n",
            "Batch: 8 / 6567\n",
            "\n",
            "Batch: 9 / 6567\n",
            "\n",
            "Batch: 10 / 6567\n",
            "\n",
            "Batch: 11 / 6567\n",
            "\n",
            "Batch: 12 / 6567\n",
            "\n",
            "Batch: 13 / 6567\n",
            "\n",
            "Batch: 14 / 6567\n",
            "\n",
            "Batch: 15 / 6567\n",
            "\n",
            "Batch: 16 / 6567\n",
            "\n",
            "Batch: 17 / 6567\n",
            "\n",
            "Batch: 18 / 6567\n",
            "\n",
            "Batch: 19 / 6567\n",
            "\n",
            "Batch: 20 / 6567\n",
            "\n",
            "Batch: 21 / 6567\n",
            "\n",
            "Batch: 22 / 6567\n",
            "\n",
            "Batch: 23 / 6567\n",
            "\n",
            "Batch: 24 / 6567\n",
            "\n",
            "Batch: 25 / 6567\n",
            "\n",
            "Batch: 26 / 6567\n",
            "\n",
            "Batch: 27 / 6567\n",
            "\n",
            "Batch: 28 / 6567\n",
            "\n",
            "Batch: 29 / 6567\n",
            "\n",
            "Batch: 30 / 6567\n",
            "\n",
            "Batch: 31 / 6567\n",
            "\n",
            "Batch: 32 / 6567\n",
            "\n",
            "Batch: 33 / 6567\n",
            "\n",
            "Batch: 34 / 6567\n",
            "\n",
            "Batch: 35 / 6567\n",
            "\n",
            "Batch: 36 / 6567\n",
            "\n",
            "Batch: 37 / 6567\n",
            "\n",
            "Batch: 38 / 6567\n",
            "\n",
            "Batch: 39 / 6567\n",
            "\n",
            "Batch: 40 / 6567\n",
            "\n",
            "Batch: 41 / 6567\n",
            "\n",
            "Batch: 42 / 6567\n",
            "\n",
            "Batch: 43 / 6567\n",
            "\n",
            "Batch: 44 / 6567\n",
            "\n",
            "Batch: 45 / 6567\n",
            "\n",
            "Batch: 46 / 6567\n",
            "\n",
            "Batch: 47 / 6567\n",
            "\n",
            "Batch: 48 / 6567\n",
            "\n",
            "Batch: 49 / 6567\n",
            "\n",
            "Batch: 50 / 6567\n",
            "\n",
            "Batch: 51 / 6567\n",
            "\n",
            "Batch: 52 / 6567\n",
            "\n",
            "Batch: 53 / 6567\n",
            "\n",
            "Batch: 54 / 6567\n",
            "\n",
            "Batch: 55 / 6567\n",
            "\n",
            "Batch: 56 / 6567\n",
            "\n",
            "Batch: 57 / 6567\n",
            "\n",
            "Batch: 58 / 6567\n",
            "\n",
            "Batch: 59 / 6567\n",
            "\n",
            "Batch: 60 / 6567\n",
            "\n",
            "Batch: 61 / 6567\n",
            "\n",
            "Batch: 62 / 6567\n",
            "\n",
            "Batch: 63 / 6567\n",
            "\n",
            "Batch: 64 / 6567\n",
            "\n",
            "Batch: 65 / 6567\n",
            "\n",
            "Batch: 66 / 6567\n",
            "\n",
            "Batch: 67 / 6567\n",
            "\n",
            "Batch: 68 / 6567\n",
            "\n",
            "Batch: 69 / 6567\n",
            "\n",
            "Batch: 70 / 6567\n",
            "\n",
            "Batch: 71 / 6567\n",
            "\n",
            "Batch: 72 / 6567\n",
            "\n",
            "Batch: 73 / 6567\n",
            "\n",
            "Batch: 74 / 6567\n",
            "\n",
            "Batch: 75 / 6567\n",
            "\n",
            "Batch: 76 / 6567\n",
            "\n",
            "Batch: 77 / 6567\n",
            "\n",
            "Batch: 78 / 6567\n",
            "\n",
            "Batch: 79 / 6567\n",
            "\n",
            "Batch: 80 / 6567\n",
            "\n",
            "Batch: 81 / 6567\n",
            "\n",
            "Batch: 82 / 6567\n",
            "\n",
            "Batch: 83 / 6567\n",
            "\n",
            "Batch: 84 / 6567\n",
            "\n",
            "Batch: 85 / 6567\n",
            "\n",
            "Batch: 86 / 6567\n",
            "\n",
            "Batch: 87 / 6567\n",
            "\n",
            "Batch: 88 / 6567\n",
            "\n",
            "Batch: 89 / 6567\n",
            "\n",
            "Batch: 90 / 6567\n",
            "\n",
            "Batch: 91 / 6567\n",
            "\n",
            "Batch: 92 / 6567\n",
            "\n",
            "Batch: 93 / 6567\n",
            "\n",
            "Batch: 94 / 6567\n",
            "\n",
            "Batch: 95 / 6567\n",
            "\n",
            "Batch: 96 / 6567\n",
            "\n",
            "Batch: 97 / 6567\n",
            "\n",
            "Batch: 98 / 6567\n",
            "\n",
            "Batch: 99 / 6567\n",
            "\n",
            "Batch: 100 / 6567\n",
            "\n",
            "Batch: 101 / 6567\n",
            "\n",
            "Batch: 102 / 6567\n",
            "\n",
            "Batch: 103 / 6567\n",
            "\n",
            "Batch: 104 / 6567\n",
            "\n",
            "Batch: 105 / 6567\n",
            "\n",
            "Batch: 106 / 6567\n",
            "\n",
            "Batch: 107 / 6567\n",
            "\n",
            "Batch: 108 / 6567\n",
            "\n",
            "Batch: 109 / 6567\n",
            "\n",
            "Batch: 110 / 6567\n",
            "\n",
            "Batch: 111 / 6567\n",
            "\n",
            "Batch: 112 / 6567\n",
            "\n",
            "Batch: 113 / 6567\n",
            "\n",
            "Batch: 114 / 6567\n",
            "\n",
            "Batch: 115 / 6567\n",
            "\n",
            "Batch: 116 / 6567\n",
            "\n",
            "Batch: 117 / 6567\n",
            "\n",
            "Batch: 118 / 6567\n",
            "\n",
            "Batch: 119 / 6567\n",
            "\n",
            "Batch: 120 / 6567\n",
            "\n",
            "Batch: 121 / 6567\n",
            "\n",
            "Batch: 122 / 6567\n",
            "\n",
            "Batch: 123 / 6567\n",
            "\n",
            "Batch: 124 / 6567\n",
            "\n",
            "Batch: 125 / 6567\n",
            "\n",
            "Batch: 126 / 6567\n",
            "\n",
            "Batch: 127 / 6567\n",
            "\n",
            "Batch: 128 / 6567\n",
            "\n",
            "Batch: 129 / 6567\n",
            "\n",
            "Batch: 130 / 6567\n",
            "\n",
            "Batch: 131 / 6567\n",
            "\n",
            "Batch: 132 / 6567\n",
            "\n",
            "Batch: 133 / 6567\n",
            "\n",
            "Batch: 134 / 6567\n",
            "\n",
            "Batch: 135 / 6567\n",
            "\n",
            "Batch: 136 / 6567\n",
            "\n",
            "Batch: 137 / 6567\n",
            "\n",
            "Batch: 138 / 6567\n",
            "\n",
            "Batch: 139 / 6567\n",
            "\n",
            "Batch: 140 / 6567\n",
            "\n",
            "Batch: 141 / 6567\n",
            "\n",
            "Batch: 142 / 6567\n",
            "\n",
            "Batch: 143 / 6567\n",
            "\n",
            "Batch: 144 / 6567\n",
            "\n",
            "Batch: 145 / 6567\n",
            "\n",
            "Batch: 146 / 6567\n",
            "\n",
            "Batch: 147 / 6567\n",
            "\n",
            "Batch: 148 / 6567\n",
            "\n",
            "Batch: 149 / 6567\n",
            "\n",
            "Batch: 150 / 6567\n",
            "\n",
            "Batch: 151 / 6567\n",
            "\n",
            "Batch: 152 / 6567\n",
            "\n",
            "Batch: 153 / 6567\n",
            "\n",
            "Batch: 154 / 6567\n",
            "\n",
            "Batch: 155 / 6567\n",
            "\n",
            "Batch: 156 / 6567\n",
            "\n",
            "Batch: 157 / 6567\n",
            "\n",
            "Batch: 158 / 6567\n",
            "\n",
            "Batch: 159 / 6567\n",
            "\n",
            "Batch: 160 / 6567\n",
            "\n",
            "Batch: 161 / 6567\n",
            "\n",
            "Batch: 162 / 6567\n",
            "\n",
            "Batch: 163 / 6567\n",
            "\n",
            "Batch: 164 / 6567\n",
            "\n",
            "Batch: 165 / 6567\n",
            "\n",
            "Batch: 166 / 6567\n",
            "\n",
            "Batch: 167 / 6567\n",
            "\n",
            "Batch: 168 / 6567\n",
            "\n",
            "Batch: 169 / 6567\n",
            "\n",
            "Batch: 170 / 6567\n",
            "\n",
            "Batch: 171 / 6567\n",
            "\n",
            "Batch: 172 / 6567\n",
            "\n",
            "Batch: 173 / 6567\n",
            "\n",
            "Batch: 174 / 6567\n",
            "\n",
            "Batch: 175 / 6567\n",
            "\n",
            "Batch: 176 / 6567\n",
            "\n",
            "Batch: 177 / 6567\n",
            "\n",
            "Batch: 178 / 6567\n",
            "\n",
            "Batch: 179 / 6567\n",
            "\n",
            "Batch: 180 / 6567\n",
            "\n",
            "Batch: 181 / 6567\n",
            "\n",
            "Batch: 182 / 6567\n",
            "\n",
            "Batch: 183 / 6567\n",
            "\n",
            "Batch: 184 / 6567\n",
            "\n",
            "Batch: 185 / 6567\n",
            "\n",
            "Batch: 186 / 6567\n",
            "\n",
            "Batch: 187 / 6567\n",
            "\n",
            "Batch: 188 / 6567\n",
            "\n",
            "Batch: 189 / 6567\n",
            "\n",
            "Batch: 190 / 6567\n",
            "\n",
            "Batch: 191 / 6567\n",
            "\n",
            "Batch: 192 / 6567\n",
            "\n",
            "Batch: 193 / 6567\n",
            "\n",
            "Batch: 194 / 6567\n",
            "\n",
            "Batch: 195 / 6567\n",
            "\n",
            "Batch: 196 / 6567\n",
            "\n",
            "Batch: 197 / 6567\n",
            "\n",
            "Batch: 198 / 6567\n",
            "\n",
            "Batch: 199 / 6567\n",
            "\n",
            "Batch: 200 / 6567\n",
            "\n",
            "Batch: 201 / 6567\n",
            "\n",
            "Batch: 202 / 6567\n",
            "\n",
            "Batch: 203 / 6567\n",
            "\n",
            "Batch: 204 / 6567\n",
            "\n",
            "Batch: 205 / 6567\n",
            "\n",
            "Batch: 206 / 6567\n",
            "\n",
            "Batch: 207 / 6567\n",
            "\n",
            "Batch: 208 / 6567\n",
            "\n",
            "Batch: 209 / 6567\n",
            "\n",
            "Batch: 210 / 6567\n",
            "\n",
            "Batch: 211 / 6567\n",
            "\n",
            "Batch: 212 / 6567\n",
            "\n",
            "Batch: 213 / 6567\n",
            "\n",
            "Batch: 214 / 6567\n",
            "\n",
            "Batch: 215 / 6567\n",
            "\n",
            "Batch: 216 / 6567\n",
            "\n",
            "Batch: 217 / 6567\n",
            "\n",
            "Batch: 218 / 6567\n",
            "\n",
            "Batch: 219 / 6567\n",
            "\n",
            "Batch: 220 / 6567\n",
            "\n",
            "Batch: 221 / 6567\n",
            "\n",
            "Batch: 222 / 6567\n",
            "\n",
            "Batch: 223 / 6567\n",
            "\n",
            "Batch: 224 / 6567\n",
            "\n",
            "Batch: 225 / 6567\n",
            "\n",
            "Batch: 226 / 6567\n",
            "\n",
            "Batch: 227 / 6567\n",
            "\n",
            "Batch: 228 / 6567\n",
            "\n",
            "Batch: 229 / 6567\n",
            "\n",
            "Batch: 230 / 6567\n",
            "\n",
            "Batch: 231 / 6567\n",
            "\n",
            "Batch: 232 / 6567\n",
            "\n",
            "Batch: 233 / 6567\n",
            "\n",
            "Batch: 234 / 6567\n",
            "\n",
            "Batch: 235 / 6567\n",
            "\n",
            "Batch: 236 / 6567\n",
            "\n",
            "Batch: 237 / 6567\n",
            "\n",
            "Batch: 238 / 6567\n",
            "\n",
            "Batch: 239 / 6567\n",
            "\n",
            "Batch: 240 / 6567\n",
            "\n",
            "Batch: 241 / 6567\n",
            "\n",
            "Batch: 242 / 6567\n",
            "\n",
            "Batch: 243 / 6567\n",
            "\n",
            "Batch: 244 / 6567\n",
            "\n",
            "Batch: 245 / 6567\n",
            "\n",
            "Batch: 246 / 6567\n",
            "\n",
            "Batch: 247 / 6567\n",
            "\n",
            "Batch: 248 / 6567\n",
            "\n",
            "Batch: 249 / 6567\n",
            "\n",
            "Batch: 250 / 6567\n",
            "\n",
            "Batch: 251 / 6567\n",
            "\n",
            "Batch: 252 / 6567\n",
            "\n",
            "Batch: 253 / 6567\n",
            "\n",
            "Batch: 254 / 6567\n",
            "\n",
            "Batch: 255 / 6567\n",
            "\n",
            "Batch: 256 / 6567\n",
            "\n",
            "Batch: 257 / 6567\n",
            "\n",
            "Batch: 258 / 6567\n",
            "\n",
            "Batch: 259 / 6567\n",
            "\n",
            "Batch: 260 / 6567\n",
            "\n",
            "Batch: 261 / 6567\n",
            "\n",
            "Batch: 262 / 6567\n",
            "\n",
            "Batch: 263 / 6567\n",
            "\n",
            "Batch: 264 / 6567\n",
            "\n",
            "Batch: 265 / 6567\n",
            "\n",
            "Batch: 266 / 6567\n",
            "\n",
            "Batch: 267 / 6567\n",
            "\n",
            "Batch: 268 / 6567\n",
            "\n",
            "Batch: 269 / 6567\n",
            "\n",
            "Batch: 270 / 6567\n",
            "\n",
            "Batch: 271 / 6567\n",
            "\n",
            "Batch: 272 / 6567\n",
            "\n",
            "Batch: 273 / 6567\n",
            "\n",
            "Batch: 274 / 6567\n",
            "\n",
            "Batch: 275 / 6567\n",
            "\n",
            "Batch: 276 / 6567\n",
            "\n",
            "Batch: 277 / 6567\n",
            "\n",
            "Batch: 278 / 6567\n",
            "\n",
            "Batch: 279 / 6567\n",
            "\n",
            "Batch: 280 / 6567\n",
            "\n",
            "Batch: 281 / 6567\n",
            "\n",
            "Batch: 282 / 6567\n",
            "\n",
            "Batch: 283 / 6567\n",
            "\n",
            "Batch: 284 / 6567\n",
            "\n",
            "Batch: 285 / 6567\n",
            "\n",
            "Batch: 286 / 6567\n",
            "\n",
            "Batch: 287 / 6567\n",
            "\n",
            "Batch: 288 / 6567\n",
            "\n",
            "Batch: 289 / 6567\n",
            "\n",
            "Batch: 290 / 6567\n",
            "\n",
            "Batch: 291 / 6567\n",
            "\n",
            "Batch: 292 / 6567\n",
            "\n",
            "Batch: 293 / 6567\n",
            "\n",
            "Batch: 294 / 6567\n",
            "\n",
            "Batch: 295 / 6567\n",
            "\n",
            "Batch: 296 / 6567\n",
            "\n",
            "Batch: 297 / 6567\n",
            "\n",
            "Batch: 298 / 6567\n",
            "\n",
            "Batch: 299 / 6567\n",
            "\n",
            "Batch: 300 / 6567\n",
            "\n",
            "Batch: 301 / 6567\n",
            "\n",
            "Batch: 302 / 6567\n",
            "\n",
            "Batch: 303 / 6567\n",
            "\n",
            "Batch: 304 / 6567\n",
            "\n",
            "Batch: 305 / 6567\n",
            "\n",
            "Batch: 306 / 6567\n",
            "\n",
            "Batch: 307 / 6567\n",
            "\n",
            "Batch: 308 / 6567\n",
            "\n",
            "Batch: 309 / 6567\n",
            "\n",
            "Batch: 310 / 6567\n",
            "\n",
            "Batch: 311 / 6567\n",
            "\n",
            "Batch: 312 / 6567\n",
            "\n",
            "Batch: 313 / 6567\n",
            "\n",
            "Batch: 314 / 6567\n",
            "\n",
            "Batch: 315 / 6567\n",
            "\n",
            "Batch: 316 / 6567\n",
            "\n",
            "Batch: 317 / 6567\n",
            "\n",
            "Batch: 318 / 6567\n",
            "\n",
            "Batch: 319 / 6567\n",
            "\n",
            "Batch: 320 / 6567\n",
            "\n",
            "Batch: 321 / 6567\n",
            "\n",
            "Batch: 322 / 6567\n",
            "\n",
            "Batch: 323 / 6567\n",
            "\n",
            "Batch: 324 / 6567\n",
            "\n",
            "Batch: 325 / 6567\n",
            "\n",
            "Batch: 326 / 6567\n",
            "\n",
            "Batch: 327 / 6567\n",
            "\n",
            "Batch: 328 / 6567\n",
            "\n",
            "Batch: 329 / 6567\n",
            "\n",
            "Batch: 330 / 6567\n",
            "\n",
            "Batch: 331 / 6567\n",
            "\n",
            "Batch: 332 / 6567\n",
            "\n",
            "Batch: 333 / 6567\n",
            "\n",
            "Batch: 334 / 6567\n",
            "\n",
            "Batch: 335 / 6567\n",
            "\n",
            "Batch: 336 / 6567\n",
            "\n",
            "Batch: 337 / 6567\n",
            "\n",
            "Batch: 338 / 6567\n",
            "\n",
            "Batch: 339 / 6567\n",
            "\n",
            "Batch: 340 / 6567\n",
            "\n",
            "Batch: 341 / 6567\n",
            "\n",
            "Batch: 342 / 6567\n",
            "\n",
            "Batch: 343 / 6567\n",
            "\n",
            "Batch: 344 / 6567\n",
            "\n",
            "Batch: 345 / 6567\n",
            "\n",
            "Batch: 346 / 6567\n",
            "\n",
            "Batch: 347 / 6567\n",
            "\n",
            "Batch: 348 / 6567\n",
            "\n",
            "Batch: 349 / 6567\n",
            "\n",
            "Batch: 350 / 6567\n",
            "\n",
            "Batch: 351 / 6567\n",
            "\n",
            "Batch: 352 / 6567\n",
            "\n",
            "Batch: 353 / 6567\n",
            "\n",
            "Batch: 354 / 6567\n",
            "\n",
            "Batch: 355 / 6567\n",
            "\n",
            "Batch: 356 / 6567\n",
            "\n",
            "Batch: 357 / 6567\n",
            "\n",
            "Batch: 358 / 6567\n",
            "\n",
            "Batch: 359 / 6567\n",
            "\n",
            "Batch: 360 / 6567\n",
            "\n",
            "Batch: 361 / 6567\n",
            "\n",
            "Batch: 362 / 6567\n",
            "\n",
            "Batch: 363 / 6567\n",
            "\n",
            "Batch: 364 / 6567\n",
            "\n",
            "Batch: 365 / 6567\n",
            "\n",
            "Batch: 366 / 6567\n",
            "\n",
            "Batch: 367 / 6567\n",
            "\n",
            "Batch: 368 / 6567\n",
            "\n",
            "Batch: 369 / 6567\n",
            "\n",
            "Batch: 370 / 6567\n",
            "\n",
            "Batch: 371 / 6567\n",
            "\n",
            "Batch: 372 / 6567\n",
            "\n",
            "Batch: 373 / 6567\n",
            "\n",
            "Batch: 374 / 6567\n",
            "\n",
            "Batch: 375 / 6567\n",
            "\n",
            "Batch: 376 / 6567\n",
            "\n",
            "Batch: 377 / 6567\n",
            "\n",
            "Batch: 378 / 6567\n",
            "\n",
            "Batch: 379 / 6567\n",
            "\n",
            "Batch: 380 / 6567\n",
            "\n",
            "Batch: 381 / 6567\n",
            "\n",
            "Batch: 382 / 6567\n",
            "\n",
            "Batch: 383 / 6567\n",
            "\n",
            "Batch: 384 / 6567\n",
            "\n",
            "Batch: 385 / 6567\n",
            "\n",
            "Batch: 386 / 6567\n",
            "\n",
            "Batch: 387 / 6567\n",
            "\n",
            "Batch: 388 / 6567\n",
            "\n",
            "Batch: 389 / 6567\n",
            "\n",
            "Batch: 390 / 6567\n",
            "\n",
            "Batch: 391 / 6567\n",
            "\n",
            "Batch: 392 / 6567\n",
            "\n",
            "Batch: 393 / 6567\n",
            "\n",
            "Batch: 394 / 6567\n",
            "\n",
            "Batch: 395 / 6567\n",
            "\n",
            "Batch: 396 / 6567\n",
            "\n",
            "Batch: 397 / 6567\n",
            "\n",
            "Batch: 398 / 6567\n",
            "\n",
            "Batch: 399 / 6567\n",
            "\n",
            "Batch: 400 / 6567\n",
            "\n",
            "Batch: 401 / 6567\n",
            "\n",
            "Batch: 402 / 6567\n",
            "\n",
            "Batch: 403 / 6567\n",
            "\n",
            "Batch: 404 / 6567\n",
            "\n",
            "Batch: 405 / 6567\n",
            "\n",
            "Batch: 406 / 6567\n",
            "\n",
            "Batch: 407 / 6567\n",
            "\n",
            "Batch: 408 / 6567\n",
            "\n",
            "Batch: 409 / 6567\n",
            "\n",
            "Batch: 410 / 6567\n",
            "\n",
            "Batch: 411 / 6567\n",
            "\n",
            "Batch: 412 / 6567\n",
            "\n",
            "Batch: 413 / 6567\n",
            "\n",
            "Batch: 414 / 6567\n",
            "\n",
            "Batch: 415 / 6567\n",
            "\n",
            "Batch: 416 / 6567\n",
            "\n",
            "Batch: 417 / 6567\n",
            "\n",
            "Batch: 418 / 6567\n",
            "\n",
            "Batch: 419 / 6567\n",
            "\n",
            "Batch: 420 / 6567\n",
            "\n",
            "Batch: 421 / 6567\n",
            "\n",
            "Batch: 422 / 6567\n",
            "\n",
            "Batch: 423 / 6567\n",
            "\n",
            "Batch: 424 / 6567\n",
            "\n",
            "Batch: 425 / 6567\n",
            "\n",
            "Batch: 426 / 6567\n",
            "\n",
            "Batch: 427 / 6567\n",
            "\n",
            "Batch: 428 / 6567\n",
            "\n",
            "Batch: 429 / 6567\n",
            "\n",
            "Batch: 430 / 6567\n",
            "\n",
            "Batch: 431 / 6567\n",
            "\n",
            "Batch: 432 / 6567\n",
            "\n",
            "Batch: 433 / 6567\n",
            "\n",
            "Batch: 434 / 6567\n",
            "\n",
            "Batch: 435 / 6567\n",
            "\n",
            "Batch: 436 / 6567\n",
            "\n",
            "Batch: 437 / 6567\n",
            "\n",
            "Batch: 438 / 6567\n",
            "\n",
            "Batch: 439 / 6567\n",
            "\n",
            "Batch: 440 / 6567\n",
            "\n",
            "Batch: 441 / 6567\n",
            "\n",
            "Batch: 442 / 6567\n",
            "\n",
            "Batch: 443 / 6567\n",
            "\n",
            "Batch: 444 / 6567\n",
            "\n",
            "Batch: 445 / 6567\n",
            "\n",
            "Batch: 446 / 6567\n",
            "\n",
            "Batch: 447 / 6567\n",
            "\n",
            "Batch: 448 / 6567\n",
            "\n",
            "Batch: 449 / 6567\n",
            "\n",
            "Batch: 450 / 6567\n",
            "\n",
            "Batch: 451 / 6567\n",
            "\n",
            "Batch: 452 / 6567\n",
            "\n",
            "Batch: 453 / 6567\n",
            "\n",
            "Batch: 454 / 6567\n",
            "\n",
            "Batch: 455 / 6567\n",
            "\n",
            "Batch: 456 / 6567\n",
            "\n",
            "Batch: 457 / 6567\n",
            "\n",
            "Batch: 458 / 6567\n",
            "\n",
            "Batch: 459 / 6567\n",
            "\n",
            "Batch: 460 / 6567\n",
            "\n",
            "Batch: 461 / 6567\n",
            "\n",
            "Batch: 462 / 6567\n",
            "\n",
            "Batch: 463 / 6567\n",
            "\n",
            "Batch: 464 / 6567\n",
            "\n",
            "Batch: 465 / 6567\n",
            "\n",
            "Batch: 466 / 6567\n",
            "\n",
            "Batch: 467 / 6567\n",
            "\n",
            "Batch: 468 / 6567\n",
            "\n",
            "Batch: 469 / 6567\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39mipnuts\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m----> 9\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# shape: [batch_size, num_classes]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ids)):\n\u001b[1;32m     12\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: ids[i],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: lats[i],\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: lons[i],\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m: probs[i]  \u001b[38;5;66;03m# This will be a NumPy array\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     })\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for batch_idx, (ipnuts, ids, lats, lons) in enumerate(test_loader):\n",
        "        # Assume each batch has the following\n",
        "        # batch = (inputs, (id, lat, lon))\n",
        "        print(f\"\\nBatch: {batch_idx} / {len(test_loader)}\")\n",
        "        inputs =ipnuts.to(device)\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        probs = F.softmax(outputs, dim=1).cpu().numpy()  # shape: [batch_size, num_classes]\n",
        "\n",
        "        for i in range(len(ids)):\n",
        "            results.append({\n",
        "                \"id\": ids[i],\n",
        "                \"latitude\": lats[i],\n",
        "                \"longitude\": lons[i],\n",
        "                \"softmax_probs\": probs[i]  # This will be a NumPy array\n",
        "            })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>softmax_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>547473234108938</td>\n",
              "      <td>tensor(-16.3360, dtype=torch.float64)</td>\n",
              "      <td>tensor(45.6283, dtype=torch.float64)</td>\n",
              "      <td>[0.009686001, 0.00047221873, 0.00042852398, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>826109781317024</td>\n",
              "      <td>tensor(50.8557, dtype=torch.float64)</td>\n",
              "      <td>tensor(56.1480, dtype=torch.float64)</td>\n",
              "      <td>[0.0069134636, 0.00048147028, 0.0003961817, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1006398440000844</td>\n",
              "      <td>tensor(37.9567, dtype=torch.float64)</td>\n",
              "      <td>tensor(14.9545, dtype=torch.float64)</td>\n",
              "      <td>[0.00867515, 0.0005090673, 0.00042162492, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2943891539215481</td>\n",
              "      <td>tensor(12.3733, dtype=torch.float64)</td>\n",
              "      <td>tensor(-8.9099, dtype=torch.float64)</td>\n",
              "      <td>[0.009685573, 0.0004990716, 0.000428763, 0.000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>122945119799579</td>\n",
              "      <td>tensor(7.5103, dtype=torch.float64)</td>\n",
              "      <td>tensor(99.0619, dtype=torch.float64)</td>\n",
              "      <td>[0.012565012, 0.00049636094, 0.00042835105, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>523784905697835</td>\n",
              "      <td>tensor(9.0405, dtype=torch.float64)</td>\n",
              "      <td>tensor(-11.7210, dtype=torch.float64)</td>\n",
              "      <td>[0.0069704424, 0.00049952534, 0.000438092, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>938982170230321</td>\n",
              "      <td>tensor(44.5749, dtype=torch.float64)</td>\n",
              "      <td>tensor(-0.8657, dtype=torch.float64)</td>\n",
              "      <td>[0.0058071865, 0.00052079814, 0.0004370921, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>333119144910637</td>\n",
              "      <td>tensor(23.7630, dtype=torch.float64)</td>\n",
              "      <td>tensor(-99.0120, dtype=torch.float64)</td>\n",
              "      <td>[0.0022568484, 0.00044630008, 0.00040570268, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2530858327060639</td>\n",
              "      <td>tensor(10.3749, dtype=torch.float64)</td>\n",
              "      <td>tensor(-6.9190, dtype=torch.float64)</td>\n",
              "      <td>[0.0059636086, 0.0005331156, 0.00044378013, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>639127933870005</td>\n",
              "      <td>tensor(26.6556, dtype=torch.float64)</td>\n",
              "      <td>tensor(127.9535, dtype=torch.float64)</td>\n",
              "      <td>[0.0063706203, 0.00051135174, 0.00039089503, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                               latitude  \\\n",
              "0   547473234108938  tensor(-16.3360, dtype=torch.float64)   \n",
              "1   826109781317024   tensor(50.8557, dtype=torch.float64)   \n",
              "2  1006398440000844   tensor(37.9567, dtype=torch.float64)   \n",
              "3  2943891539215481   tensor(12.3733, dtype=torch.float64)   \n",
              "4   122945119799579    tensor(7.5103, dtype=torch.float64)   \n",
              "5   523784905697835    tensor(9.0405, dtype=torch.float64)   \n",
              "6   938982170230321   tensor(44.5749, dtype=torch.float64)   \n",
              "7   333119144910637   tensor(23.7630, dtype=torch.float64)   \n",
              "8  2530858327060639   tensor(10.3749, dtype=torch.float64)   \n",
              "9   639127933870005   tensor(26.6556, dtype=torch.float64)   \n",
              "\n",
              "                               longitude  \\\n",
              "0   tensor(45.6283, dtype=torch.float64)   \n",
              "1   tensor(56.1480, dtype=torch.float64)   \n",
              "2   tensor(14.9545, dtype=torch.float64)   \n",
              "3   tensor(-8.9099, dtype=torch.float64)   \n",
              "4   tensor(99.0619, dtype=torch.float64)   \n",
              "5  tensor(-11.7210, dtype=torch.float64)   \n",
              "6   tensor(-0.8657, dtype=torch.float64)   \n",
              "7  tensor(-99.0120, dtype=torch.float64)   \n",
              "8   tensor(-6.9190, dtype=torch.float64)   \n",
              "9  tensor(127.9535, dtype=torch.float64)   \n",
              "\n",
              "                                       softmax_probs  \n",
              "0  [0.009686001, 0.00047221873, 0.00042852398, 0....  \n",
              "1  [0.0069134636, 0.00048147028, 0.0003961817, 0....  \n",
              "2  [0.00867515, 0.0005090673, 0.00042162492, 0.00...  \n",
              "3  [0.009685573, 0.0004990716, 0.000428763, 0.000...  \n",
              "4  [0.012565012, 0.00049636094, 0.00042835105, 0....  \n",
              "5  [0.0069704424, 0.00049952534, 0.000438092, 0.0...  \n",
              "6  [0.0058071865, 0.00052079814, 0.0004370921, 0....  \n",
              "7  [0.0022568484, 0.00044630008, 0.00040570268, 0...  \n",
              "8  [0.0059636086, 0.0005331156, 0.00044378013, 0....  \n",
              "9  [0.0063706203, 0.00051135174, 0.00039089503, 0...  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base_1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
